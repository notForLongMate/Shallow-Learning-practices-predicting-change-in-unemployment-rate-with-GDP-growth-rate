  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first step I should do is inject the processed dataset in my excel file into the environment with the help of pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWsZ-tHuxWAT",
    "outputId": "8b5e4387-5a4e-42e5-f586-198e7135839d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>GDP Growth Rate</th>\n",
       "      <th>% change in unemployment rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>13.4</td>\n",
       "      <td>-39.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988</td>\n",
       "      <td>8.5</td>\n",
       "      <td>-17.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1989</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-21.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.8</td>\n",
       "      <td>18.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1991</td>\n",
       "      <td>5.7</td>\n",
       "      <td>38.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1992</td>\n",
       "      <td>6.2</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1993</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1994</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1995</td>\n",
       "      <td>2.4</td>\n",
       "      <td>68.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1996</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1997</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-21.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1998</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>113.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1999</td>\n",
       "      <td>2.5</td>\n",
       "      <td>31.914894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2000</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-20.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.081633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2002</td>\n",
       "      <td>1.7</td>\n",
       "      <td>43.137255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2003</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8.219178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2004</td>\n",
       "      <td>8.7</td>\n",
       "      <td>-13.924051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2005</td>\n",
       "      <td>7.4</td>\n",
       "      <td>-17.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2006</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2007</td>\n",
       "      <td>6.5</td>\n",
       "      <td>-16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2008</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2009</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>51.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2010</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-18.867925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2011</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-20.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2012</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-2.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2013</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2014</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-2.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2015</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2017</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-8.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-9.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021</td>\n",
       "      <td>6.5</td>\n",
       "      <td>-10.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2022</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-17.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2023 r</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-32.558140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024 r</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.448276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  GDP Growth Rate  % change in unemployment rate\n",
       "0     1987             13.4                     -39.285714\n",
       "1     1988              8.5                     -17.647059\n",
       "2     1989              2.3                     -21.428571\n",
       "3     1990              3.8                      18.181818\n",
       "4     1991              5.7                      38.461538\n",
       "5     1992              6.2                      11.111111\n",
       "6     1993              6.2                       0.000000\n",
       "7     1994              6.0                      -5.000000\n",
       "8     1995              2.4                      68.421053\n",
       "9     1996              4.3                     -12.500000\n",
       "10    1997              5.1                     -21.428571\n",
       "11    1998             -5.9                     113.636364\n",
       "12    1999              2.5                      31.914894\n",
       "13    2000              7.7                     -20.967742\n",
       "14    2001              0.6                       4.081633\n",
       "15    2002              1.7                      43.137255\n",
       "16    2003              3.1                       8.219178\n",
       "17    2004              8.7                     -13.924051\n",
       "18    2005              7.4                     -17.647059\n",
       "19    2006              7.0                     -14.285714\n",
       "20    2007              6.5                     -16.666667\n",
       "21    2008              2.1                     -12.500000\n",
       "22    2009             -2.5                      51.428571\n",
       "23    2010              6.8                     -18.867925\n",
       "24    2011              4.8                     -20.930233\n",
       "25    2012              1.7                      -2.941176\n",
       "26    2013              3.1                       3.030303\n",
       "27    2014              2.8                      -2.941176\n",
       "28    2015              2.4                       0.000000\n",
       "29    2016              2.2                       3.030303\n",
       "30    2017              3.8                      -8.823529\n",
       "31    2018              2.8                      -9.677419\n",
       "32    2019             -1.7                       3.571429\n",
       "33    2020             -6.5                     100.000000\n",
       "34    2021              6.5                     -10.344828\n",
       "35    2022             -3.7                     -17.307692\n",
       "36  2023 r              3.2                     -32.558140\n",
       "37  2024 r              2.5                       3.448276"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3.2 Data retrieval: Retrieval the processed data from the CSV file\n",
    "import pandas as pd\n",
    "data_GDPnUnemployment = pd.read_csv(r\"C:\\Users\\nicet\\OneDrive - The Chinese University of Hong Kong\\ENGG1003\\Engg Project\\ProcessedData.csv\")\n",
    "# clear all na values in the dataframe\n",
    "data_GDPnUnemployment = data_GDPnUnemployment.dropna()\n",
    "# Change the column 1's name to 'Year', column 2's name to 'GDP' and column 3's name to 'Unemployment Rate' for easier understanding\n",
    "data_GDPnUnemployment.rename(columns={data_GDPnUnemployment.columns[0]: 'Year'}, inplace=True)\n",
    "data_GDPnUnemployment.rename(columns={data_GDPnUnemployment.columns[1]: 'GDP Growth Rate'}, inplace=True)\n",
    "data_GDPnUnemployment.rename(columns={data_GDPnUnemployment.columns[2]: '% change in unemployment rate'}, inplace=True)\n",
    "# seperate the data into 2 dataframes, one for x-axis (input) and one for y-axis (output)\n",
    "x = data_GDPnUnemployment['GDP Growth Rate']\n",
    "y = data_GDPnUnemployment['% change in unemployment rate']\n",
    "# Show Data\n",
    "data_GDPnUnemployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Before building up the machine learning model, I have to plot the scatter graph in order to see the relationship between GDP growth rate and % change of Unemployment Rate in my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6BWShKC04IEh",
    "outputId": "f24dea6b-4dc4-4131-dfd4-b2a8b957849d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 3.5 Data visualization: Visualize the data using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(30, 10))\n",
    "# Plot the GDP data\n",
    "plt.scatter(x, y, color='b', label='GDP Growth Rate vs % change in Unemployment Rate')\n",
    "# Set the title and labels\n",
    "plt.title('GDP Growth Rate vs % change in Unemployment Rate')\n",
    "plt.xlabel('GDP Growth Rate')\n",
    "plt.ylabel('% change in Unemployment Rate')\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "# Show the grid\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Based on the observation, the data exhibits a negative linear trend. Therefore I believe the best fit of the alogrithm is a simple linear model. But before starting to build the model, I need to seperate the data set into two parts, the training set and the testing setss.THe process will be done using sklearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  19    7.0\n",
      "36    3.2\n",
      "23    6.8\n",
      "28    2.4\n",
      "14    0.6\n",
      "1     8.5\n",
      "34    6.5\n",
      "24    4.8\n",
      "35   -3.7\n",
      "29    2.2\n",
      "10    5.1\n",
      "4     5.7\n",
      "6     6.2\n",
      "3     3.8\n",
      "32   -1.7\n",
      "5     6.2\n",
      "25    1.7\n",
      "20    6.5\n",
      "26    3.1\n",
      "37    2.5\n",
      "21    2.1\n",
      "33   -6.5\n",
      "17    8.7\n",
      "2     2.3\n",
      "7     6.0\n",
      "11   -5.9\n",
      "18    7.4\n",
      "22   -2.5\n",
      "8     2.4\n",
      "15    1.7\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "x_test:  9      4.3\n",
      "0     13.4\n",
      "31     2.8\n",
      "12     2.5\n",
      "13     7.7\n",
      "30     3.8\n",
      "16     3.1\n",
      "27     2.8\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "y_train:  19    -14.285714\n",
      "36    -32.558140\n",
      "23    -18.867925\n",
      "28      0.000000\n",
      "14      4.081633\n",
      "1     -17.647059\n",
      "34    -10.344828\n",
      "24    -20.930233\n",
      "35    -17.307692\n",
      "29      3.030303\n",
      "10    -21.428571\n",
      "4      38.461538\n",
      "6       0.000000\n",
      "3      18.181818\n",
      "32      3.571429\n",
      "5      11.111111\n",
      "25     -2.941176\n",
      "20    -16.666667\n",
      "26      3.030303\n",
      "37      3.448276\n",
      "21    -12.500000\n",
      "33    100.000000\n",
      "17    -13.924051\n",
      "2     -21.428571\n",
      "7      -5.000000\n",
      "11    113.636364\n",
      "18    -17.647059\n",
      "22     51.428571\n",
      "8      68.421053\n",
      "15     43.137255\n",
      "Name: % change in unemployment rate, dtype: float64\n",
      "y_test:  9    -12.500000\n",
      "0    -39.285714\n",
      "31    -9.677419\n",
      "12    31.914894\n",
      "13   -20.967742\n",
      "30    -8.823529\n",
      "16     8.219178\n",
      "27    -2.941176\n",
      "Name: % change in unemployment rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Task 3.6 Data Modeling: Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "# Show the data\n",
    "print(\"x_train: \", x_train)\n",
    "print(\"x_test: \", x_test)\n",
    "print(\"y_train: \", y_train)\n",
    "print(\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. After spliting the data, we can finally set up the model. Since we decided to use a simple linear model for prediction, the function form should only be y = w*x + b, where w stands for weights (as well as the slope of the predict line) and b stands for bias (as well as the y-intercept of the predict line). At the starting point, we should first assign a random numbers to w and x, here I used random function from numpy for them. Moreover, for easier control of variables, I will set the random seed to 42 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  [0.37454012]\n",
      "Bias:  [0.95071431]\n"
     ]
    }
   ],
   "source": [
    "# Task 3.7 Data Modeling: Assign random values to the weights and bias\n",
    "import numpy as np\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "# Assign random values to the weights and bias\n",
    "w = np.random.rand(1)\n",
    "b = np.random.rand(1)\n",
    "# Show the weights and bias\n",
    "print(\"Weights: \", w)\n",
    "print(\"Bias: \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. after that, we can start build up the simple linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real % change in Unemployment Rate: -14.28571429, Predicted % change in Unemployment Rate: 3.5724951383414534\n",
      "Real % change in Unemployment Rate: -32.55813953, Predicted % change in Unemployment Rate: 2.1492426867214762\n",
      "Real % change in Unemployment Rate: -18.86792453, Predicted % change in Unemployment Rate: 3.497587114571981\n",
      "Real % change in Unemployment Rate: 0.0, Predicted % change in Unemployment Rate: 1.849610591643586\n",
      "Real % change in Unemployment Rate: 4.081632653, Predicted % change in Unemployment Rate: 1.1754383777183337\n",
      "Real % change in Unemployment Rate: -17.64705882, Predicted % change in Unemployment Rate: 4.1343053166124974\n",
      "Real % change in Unemployment Rate: -10.34482759, Predicted % change in Unemployment Rate: 3.3852250789177725\n",
      "Real % change in Unemployment Rate: -20.93023256, Predicted % change in Unemployment Rate: 2.748506876877256\n",
      "Real % change in Unemployment Rate: -17.30769231, Predicted % change in Unemployment Rate: -0.43508413332532503\n",
      "Real % change in Unemployment Rate: 3.03030303, Predicted % change in Unemployment Rate: 1.7747025678741137\n",
      "Real % change in Unemployment Rate: -21.42857143, Predicted % change in Unemployment Rate: 2.8608689125314646\n",
      "Real % change in Unemployment Rate: 38.46153846, Predicted % change in Unemployment Rate: 3.0855929838398826\n",
      "Real % change in Unemployment Rate: 0.0, Predicted % change in Unemployment Rate: 3.2728630432635635\n",
      "Real % change in Unemployment Rate: 18.18181818, Predicted % change in Unemployment Rate: 2.3739667580298933\n",
      "Real % change in Unemployment Rate: 3.571428571, Predicted % change in Unemployment Rate: 0.31399610436939995\n",
      "Real % change in Unemployment Rate: 11.11111111, Predicted % change in Unemployment Rate: 3.2728630432635635\n",
      "Real % change in Unemployment Rate: -2.941176471, Predicted % change in Unemployment Rate: 1.5874325084504324\n",
      "Real % change in Unemployment Rate: -16.66666667, Predicted % change in Unemployment Rate: 3.3852250789177725\n",
      "Real % change in Unemployment Rate: 3.03030303, Predicted % change in Unemployment Rate: 2.11178867483674\n",
      "Real % change in Unemployment Rate: 3.448275862, Predicted % change in Unemployment Rate: 1.8870646035283225\n",
      "Real % change in Unemployment Rate: -12.5, Predicted % change in Unemployment Rate: 1.7372485559893773\n",
      "Real % change in Unemployment Rate: 100.0, Predicted % change in Unemployment Rate: -1.4837964660979401\n",
      "Real % change in Unemployment Rate: -13.92405063, Predicted % change in Unemployment Rate: 4.20921334038197\n",
      "Real % change in Unemployment Rate: -21.42857143, Predicted % change in Unemployment Rate: 1.8121565797588497\n",
      "Real % change in Unemployment Rate: -5.0, Predicted % change in Unemployment Rate: 3.197955019494091\n",
      "Real % change in Unemployment Rate: 113.6363636, Predicted % change in Unemployment Rate: -1.2590723947895226\n",
      "Real % change in Unemployment Rate: -17.64705882, Predicted % change in Unemployment Rate: 3.7223111858803986\n",
      "Real % change in Unemployment Rate: 51.42857143, Predicted % change in Unemployment Rate: 0.014364009291509938\n",
      "Real % change in Unemployment Rate: 68.42105263, Predicted % change in Unemployment Rate: 1.849610591643586\n",
      "Real % change in Unemployment Rate: 43.1372549, Predicted % change in Unemployment Rate: 1.5874325084504324\n"
     ]
    }
   ],
   "source": [
    "# Task 3.7 Data Modeling: predict the output using the simple linear model with training data\n",
    "y_pred = w * x_train + b\n",
    "# Show the original output alongside the predicted output\n",
    "for pred, actual in zip(y_pred, y_train):\n",
    "\tprint(f\"Real % change in Unemployment Rate: {actual}, Predicted % change in Unemployment Rate: {pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. As expected, the predicted output is far from the % change in real unemployment rate (since we assign the w and b randomly), but we are also interested in how far away it is from the real unemployment rate. To know more about it, we should introduce the cost function, a fair measurement of the cost/loss of our machine learning model. There are many ways of calculating the cost, in here I will use the Mean Squared Error (MSE). Although it is possible to use natrual pytrhon function to calculate MSE (by doing (y_train-y_pred)**2/len(y_train)), I will choose to compute the required amount with mean_squared_error function for simplixity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  1334.7476105469098\n"
     ]
    }
   ],
   "source": [
    "# Task 3.7 Data Modeling: Calculate the cost using Mean Squared Error (MSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Calculate the cost using Mean Squared Error (MSE)\n",
    "cost = mean_squared_error(y_train, y_pred)\n",
    "# Show the cost\n",
    "print(\"cost: \", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. After acknowledging the how much is the cost, the next step we should do is to learn about the shape of the cost function and decide which way to go (i.e. w/b increase/decrease) in order to reduce the cost. For that, calculating the gradient of w and b will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of the cost function with respect to the weights:  157.8984320609515\n",
      "Gradient of the cost function with respect to the bias:  -10.311390274534206\n"
     ]
    }
   ],
   "source": [
    "# Task 3.7 Data Modeling: Calculate the gradient of the cost function with respect to the weights and bias\n",
    "# Convert x_train and y_train to numpy arrays to avoid issues with pandas Series\n",
    "x_train_np = x_train.to_numpy()\n",
    "y_train_np = y_train.to_numpy()\n",
    "\n",
    "# Calculate the gradients\n",
    "dW = 2 * (x_train_np * (w * x_train_np + b - y_train_np)).mean()\n",
    "dB = 2 * ((w * x_train_np + b - y_train_np)).mean()\n",
    "print(\"Gradient of the cost function with respect to the weights: \", dW)\n",
    "print(\"Gradient of the cost function with respect to the bias: \", dB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. After the step of calculating the gradients, we got the direction to go, the next step is follow the direction and walk for certain time (set by user) until we arrive the local minimum (i.e. Gradient ==0), this step is called gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weights:  [-1.2044442]\n",
      "Updated Bias:  [1.05382821]\n"
     ]
    }
   ],
   "source": [
    "# Task 3.7 Data Modeling: Update the weights and bias using Gradient Descent\n",
    "# Set the Learning Rate (To control the step size in the gradient descent update)\n",
    "learning_rate = 0.01\n",
    "# Update the weights and bias using Gradient Descent\n",
    "w -= learning_rate * dW\n",
    "b -= learning_rate * dB\n",
    "# Show the updated weights and bias\n",
    "print(\"Updated Weights: \", w)\n",
    "print(\"Updated Bias: \", b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. After updating w and b, we can test it with the same training dataset to see whether the accuracy of the model has been improved or not, which means we have to repeat the above act and find the cost of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real % change in Unemployment Rate: -14.28571429, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -32.55813953, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -18.86792453, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 0.0, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 4.081632653, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -17.64705882, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -10.34482759, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -20.93023256, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -17.30769231, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 3.03030303, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -21.42857143, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 38.46153846, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 0.0, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 18.18181818, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 3.571428571, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 11.11111111, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -2.941176471, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -16.66666667, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 3.03030303, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 3.448275862, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -12.5, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 100.0, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -13.92405063, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -21.42857143, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -5.0, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 113.6363636, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: -17.64705882, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 51.42857143, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 68.42105263, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "Real % change in Unemployment Rate: 43.1372549, Predicted % change in Unemployment Rate: 19   -7.377281\n",
      "36   -2.800393\n",
      "23   -7.136392\n",
      "28   -1.836838\n",
      "14    0.331162\n",
      "1    -9.183948\n",
      "34   -6.775059\n",
      "24   -4.727504\n",
      "35    5.510272\n",
      "29   -1.595949\n",
      "10   -5.088837\n",
      "4    -5.811504\n",
      "6    -6.413726\n",
      "3    -3.523060\n",
      "32    3.101383\n",
      "5    -6.413726\n",
      "25   -0.993727\n",
      "20   -6.775059\n",
      "26   -2.679949\n",
      "37   -1.957282\n",
      "21   -1.475505\n",
      "33    8.882716\n",
      "17   -9.424836\n",
      "2    -1.716393\n",
      "7    -6.172837\n",
      "11    8.160049\n",
      "18   -7.859059\n",
      "22    4.064939\n",
      "8    -1.836838\n",
      "15   -0.993727\n",
      "Name: GDP Growth Rate, dtype: float64\n",
      "cost:  1145.6527098237998\n"
     ]
    }
   ],
   "source": [
    "# Task 3.7 Data Modeling: Predict the output using the updated weights and bias\n",
    "# I am overwriting the previous y_pred variable as it have no value to us now\n",
    "y_pred = w * x_train + b\n",
    "# Show the original output alongside the predicted output\n",
    "for pred, actual in zip(y_pred, y_train):\n",
    "    print(f\"Real % change in Unemployment Rate: {actual}, Predicted % change in Unemployment Rate: {y_pred}\")\n",
    "# Task 3.7 Data Modeling: Calculate the cost using Mean Squared Error (MSE)\n",
    "cost = mean_squared_error(y_train, y_pred)\n",
    "# Show the cost\n",
    "print(\"cost: \", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. After one gradient descent process, we can discover that the cost actually decreased from 1334.7476105469098 to 1145.6527098237998, the next step we are going to do is to repeat the gradient descent procecss in certain time called iteration or updates, after finishing those certain iteration or updates, we said that a epoch is completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, I have used the Adagrad's adaptive learning rate to enhance the performance of my model, the detailed steps will be shown below: First, I assigned two variables dW_SS(dB_SS) where SS stands for sum of squres and t for time (technically this variable can be replaced with i in for loop, but I seperate them here for a clearer presentation). Then I calculate the gradient of w or b and assign them as dW(dB), squre them up and add them to dW_SS(dB_SS) than assign the dw_RMS as square root of dW_SS(dB_SS) / (t+1), in here RMS means the root mean square of the gradient. Then we manipulate the updating variable process as w - learning_rate * dW / dW_RMS(b - learning rate * dB / dW_RMS). Therefore, when the Gradient of variable gets high, the RMS of it also gets high and adjust the learning rate to lower, vice versa [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, Cost: 1144.86, Weight: [-1.2144442], gradient of w: 79.64289512041591\n",
      "iteration 1000, Cost: 1082.18, Weight: [-2.79838589], gradient of w: 4.748084308895765e-06\n",
      "iteration 2000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 3.107440231057505e-13\n",
      "iteration 3000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 2.4253192047278086e-13\n",
      "iteration 4000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 2.1979455292845766e-13\n",
      "iteration 5000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 2.0084674664152165e-13\n",
      "iteration 6000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.8095155004023884e-13\n",
      "iteration 7000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.5821418249591563e-13\n",
      "iteration 8000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.5821418249591563e-13\n",
      "iteration 9000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.4305593746636683e-13\n",
      "iteration 10000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.4305593746636683e-13\n",
      "iteration 11000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.1273944740726923e-13\n",
      "iteration 12000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.1273944740726923e-13\n",
      "iteration 13000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.1273944740726923e-13\n",
      "iteration 14000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.1273944740726923e-13\n",
      "iteration 15000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.1273944740726923e-13\n",
      "iteration 16000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.1273944740726923e-13\n",
      "iteration 17000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 9.568642174902683e-14\n",
      "iteration 18000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 9.568642174902683e-14\n",
      "iteration 19000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 9.568642174902683e-14\n",
      "iteration 20000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 9.568642174902683e-14\n",
      "iteration 21000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 9.568642174902683e-14\n",
      "iteration 22000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 9.568642174902683e-14\n",
      "iteration 23000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 24000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 25000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 26000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 27000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 28000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 29000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 30000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 31000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 32000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 33000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 34000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 35000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 36000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 37000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 38000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 39000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 7.294905420470362e-14\n",
      "iteration 40000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 41000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 42000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 43000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 44000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 45000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 46000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 47000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 48000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 49000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 50000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 51000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 52000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 53000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 54000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 55000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 56000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 57000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 58000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 59000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 60000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 61000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 62000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 5.779080917515481e-14\n",
      "iteration 63000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 64000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 65000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 66000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 67000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 68000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 69000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 70000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 71000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 72000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 73000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 74000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 75000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 76000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 77000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 78000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 79000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 80000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 81000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 82000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 83000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 84000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 85000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 86000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 87000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 88000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 89000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 90000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 91000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 92000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 93000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 94000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 95000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 96000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 97000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 98000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 99000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 100000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 101000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 102000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 103000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 104000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 105000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 106000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 107000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 108000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 109000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 110000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 111000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 112000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 113000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 114000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 115000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 116000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 117000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 118000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 119000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 120000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 121000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 122000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 123000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 124000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 125000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 126000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 127000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 128000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 129000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 130000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 131000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 132000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 133000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 134000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 135000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 136000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 137000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 138000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 139000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 140000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 141000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 142000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 143000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 144000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 145000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 146000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 147000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 148000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 149000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 150000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 151000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 152000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 153000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 154000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 155000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 156000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 157000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 158000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 159000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 160000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 161000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 162000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 163000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 164000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 165000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 166000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 167000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 168000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 169000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 170000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 171000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 172000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 173000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 174000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 175000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 176000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 177000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 178000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 179000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 180000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 181000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 182000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 183000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 184000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 185000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 186000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 187000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 188000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 189000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 190000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 191000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 192000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 193000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 194000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 195000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 196000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 197000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 198000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 199000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 200000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 201000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 202000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 203000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 204000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 205000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 206000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 207000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 208000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 209000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 210000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 211000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 212000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 213000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 214000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 215000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 216000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 217000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 218000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 219000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 220000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 221000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 222000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 223000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 224000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 225000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 226000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 227000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 228000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 229000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 230000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 231000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 232000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 233000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 234000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 235000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 236000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 237000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 238000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 239000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 240000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 241000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 242000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 243000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 244000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 245000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 246000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 247000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 248000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 249000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 250000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 251000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 252000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 253000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 254000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 255000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 256000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 257000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 258000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 259000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 260000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 261000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 262000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 263000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 264000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 265000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 266000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 267000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 268000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 269000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 270000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 271000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 272000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 273000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 274000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 275000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 276000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 277000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 278000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 279000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 280000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 281000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 282000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 283000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 284000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 285000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 286000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 287000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 288000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 289000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 290000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 291000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 292000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 293000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 294000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 295000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 296000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 297000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 298000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 299000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 300000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 301000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 302000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 303000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 304000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 305000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 306000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 307000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 308000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 309000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 310000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 311000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 312000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 313000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 314000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 315000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 316000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 317000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 318000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 319000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 320000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 321000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 322000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 323000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 324000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 325000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 326000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 327000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 328000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 329000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 330000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 331000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 332000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 333000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 334000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 335000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 336000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 337000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 338000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 339000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 340000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 341000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 342000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 343000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 344000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 345000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 346000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 347000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 348000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 349000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 350000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 351000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 352000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 353000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 354000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 355000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 356000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 357000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 358000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 359000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 360000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 361000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 362000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 363000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 364000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 365000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 366000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 367000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 368000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 369000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 370000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 371000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 372000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 373000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 374000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 375000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 376000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 377000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 378000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 379000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 380000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 381000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 382000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 383000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 384000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 385000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 386000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 387000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 388000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 389000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 390000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 391000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 392000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 393000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 394000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 395000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 396000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 397000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 398000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 399000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 400000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 401000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 402000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 403000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 404000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 405000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 406000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 407000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 408000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 409000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 410000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 411000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 412000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 413000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 414000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 415000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 416000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 417000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 418000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 419000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 420000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 421000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 422000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 423000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 424000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 425000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 426000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 427000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 428000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 429000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 430000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 431000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 432000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 433000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 434000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 435000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 436000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 437000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 438000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 439000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 440000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 441000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 442000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 443000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 444000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 445000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 446000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 447000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 448000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 449000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 450000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 451000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 452000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 453000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 454000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 455000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 456000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 457000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 458000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 459000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 460000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 461000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 462000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 463000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 464000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 465000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 466000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 467000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 468000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 469000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 470000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 471000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 472000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 473000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 474000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 475000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 476000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 477000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 478000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 479000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 480000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 481000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 482000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 483000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 484000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 485000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 486000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 487000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 488000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 489000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 490000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 491000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 492000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 493000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 494000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 495000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 496000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 497000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 498000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 499000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 500000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 501000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 502000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 503000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 504000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 505000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 506000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 507000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 508000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 509000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 510000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 511000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 512000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 513000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 514000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 515000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 516000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 517000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 518000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 519000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 520000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 521000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 522000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 523000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 524000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 525000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: 1.9895196601282804e-14\n",
      "iteration 526000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 527000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 528000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 529000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 530000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 531000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 532000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 533000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 534000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 535000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 536000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 537000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 538000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 539000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 540000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 541000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 542000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 543000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 544000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 545000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 546000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 547000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 548000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 549000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 550000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 551000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 552000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 553000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 554000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 555000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 556000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 557000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 558000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 559000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 560000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 561000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 562000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 563000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 564000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 565000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 566000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 567000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 568000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 569000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 570000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 571000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 572000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 573000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 574000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 575000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 576000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 577000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 578000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 579000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 580000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 581000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 582000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 583000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 584000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 585000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 586000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 587000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 588000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 589000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 590000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 591000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 592000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 593000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 594000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 595000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 596000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 597000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 598000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 599000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 600000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 601000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 602000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 603000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 604000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 605000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 606000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 607000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 608000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 609000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 610000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 611000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 612000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 613000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 614000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 615000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 616000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 617000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 618000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 619000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 620000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 621000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 622000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 623000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 624000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 625000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 626000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 627000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 628000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 629000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 630000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 631000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 632000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 633000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 634000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 635000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 636000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 637000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 638000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 639000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 640000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 641000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 642000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 643000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 644000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 645000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 646000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 647000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 648000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 649000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 650000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 651000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 652000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 653000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 654000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 655000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 656000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 657000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 658000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 659000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 660000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 661000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 662000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 663000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 664000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 665000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 666000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 667000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 668000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 669000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 670000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 671000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 672000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 673000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 674000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 675000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 676000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 677000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 678000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 679000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 680000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 681000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 682000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 683000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 684000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 685000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 686000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 687000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 688000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 689000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 690000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 691000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 692000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 693000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 694000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 695000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 696000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 697000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 698000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 699000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 700000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 701000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 702000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 703000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 704000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 705000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 706000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 707000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 708000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 709000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 710000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 711000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 712000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 713000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 714000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 715000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 716000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 717000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 718000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 719000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 720000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 721000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 722000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 723000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 724000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 725000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 726000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 727000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 728000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 729000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 730000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 731000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 732000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 733000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 734000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 735000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 736000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 737000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 738000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 739000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 740000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 741000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 742000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 743000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 744000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 745000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 746000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 747000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 748000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 749000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 750000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 751000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 752000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 753000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 754000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 755000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 756000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 757000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 758000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 759000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 760000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 761000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 762000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 763000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 764000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 765000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 766000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 767000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 768000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 769000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 770000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 771000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 772000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 773000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 774000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 775000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 776000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 777000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 778000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 779000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 780000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 781000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 782000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 783000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 784000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 785000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 786000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 787000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 788000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 789000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 790000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 791000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 792000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 793000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 794000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 795000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 796000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 797000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 798000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 799000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 800000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 801000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 802000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 803000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 804000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 805000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 806000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 807000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 808000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 809000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 810000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 811000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 812000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 813000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 814000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 815000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 816000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 817000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 818000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 819000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 820000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 821000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 822000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 823000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 824000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 825000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 826000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 827000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 828000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 829000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 830000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 831000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 832000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 833000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 834000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 835000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 836000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 837000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 838000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 839000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 840000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 841000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 842000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 843000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 844000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 845000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 846000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 847000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 848000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 849000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 850000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 851000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 852000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 853000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 854000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 855000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 856000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 857000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 858000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 859000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 860000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 861000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 862000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 863000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 864000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 865000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 866000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 867000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 868000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 869000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 870000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 871000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 872000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 873000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 874000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 875000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 876000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 877000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 878000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 879000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 880000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 881000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 882000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 883000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 884000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 885000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 886000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 887000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 888000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 889000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 890000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 891000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 892000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 893000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 894000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 895000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 896000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 897000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 898000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 899000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 900000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 901000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 902000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 903000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 904000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 905000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 906000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 907000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 908000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 909000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 910000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 911000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 912000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 913000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 914000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 915000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 916000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 917000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 918000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 919000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 920000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 921000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 922000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 923000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 924000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 925000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 926000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 927000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 928000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 929000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 930000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 931000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 932000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 933000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 934000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 935000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 936000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 937000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 938000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 939000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 940000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 941000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 942000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 943000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 944000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 945000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 946000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 947000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 948000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 949000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 950000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 951000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 952000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 953000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 954000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 955000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 956000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 957000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 958000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 959000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 960000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 961000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 962000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 963000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 964000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 965000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 966000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 967000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 968000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 969000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 970000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 971000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 972000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 973000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 974000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 975000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 976000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 977000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 978000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 979000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 980000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 981000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 982000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 983000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 984000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 985000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 986000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 987000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 988000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 989000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 990000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 991000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 992000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 993000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 994000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 995000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 996000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 997000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 998000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n",
      "iteration 999000, Cost: 1082.18, Weight: [-2.79838598], gradient of w: -6.631732200427602e-15\n"
     ]
    }
   ],
   "source": [
    "# Task 3.7 Data Modeling: Automate the process of Gradient Descent using for loop, targeting 10000 iterations as an epoch\n",
    "epochs = 100\n",
    "# Set the hyperparameters and initialize the variables\n",
    "learning_rate = 0.01\n",
    "dW_SS = 0\n",
    "t = 0\n",
    "# Using for loop to automate the process of Gradient Descent\n",
    "for i in range(epochs*10000):\n",
    "    # Calculate the gradient of w\n",
    "    dW = 2 * (x_train_np * (w * x_train_np + b - y_train_np)).mean()\n",
    "    # Update the mean square value of the gradient of w\n",
    "    dW_SS += dW**2\n",
    "    dW_RMS = np.sqrt(dW_SS / (t + 1))\n",
    "    # Update the weights\n",
    "    w -= learning_rate * dW / dW_RMS\n",
    "    # Recalculate y_pred after updating weights\n",
    "    y_pred = w * x_train_np + b\n",
    "    # Calculate the cost using Mean Squared Error (MSE)\n",
    "    cost = mean_squared_error(y_train_np, y_pred)\n",
    "    t += 1\n",
    "    # Show the cost every 1000 iterations\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"iteration {i}, Cost: {cost:.2f}, Weight: {w}, gradient of w: {dW}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, Cost: 1081.88, bias: [1.06382821], gradient of b: -29.798457150999997\n",
      "iteration 1000, Cost: 905.33, bias: [9.23428848], gradient of b: -13.45003448055331\n",
      "iteration 2000, Cost: 865.47, bias: [13.65657101], gradient of b: -4.598562372743387\n",
      "iteration 3000, Cost: 860.55, bias: [15.35845606], gradient of b: -1.1909623668566183\n",
      "iteration 4000, Cost: 860.21, bias: [15.83259484], gradient of b: -0.2413357505754225\n",
      "iteration 5000, Cost: 860.19, bias: [15.93335911], gradient of b: -0.03947065541106388\n",
      "iteration 6000, Cost: 860.19, bias: [15.95039743], gradient of b: -0.005329853610330796\n",
      "iteration 7000, Cost: 860.19, bias: [15.95275533], gradient of b: -0.0006042775238829753\n",
      "iteration 8000, Cost: 860.19, bias: [15.95302772], gradient of b: -5.827603333964741e-05\n",
      "iteration 9000, Cost: 860.19, bias: [15.95305438], gradient of b: -4.830848535182971e-06\n",
      "iteration 10000, Cost: 860.19, bias: [15.95305661], gradient of b: -3.4721527531663317e-07\n",
      "iteration 11000, Cost: 860.19, bias: [15.95305677], gradient of b: -2.1796975128533327e-08\n",
      "iteration 12000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2027034775504338e-09\n",
      "iteration 13000, Cost: 860.19, bias: [15.95305678], gradient of b: -5.864440784838129e-11\n",
      "iteration 14000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.5683751421941753e-12\n",
      "iteration 15000, Cost: 860.19, bias: [15.95305678], gradient of b: -5.366966130774623e-13\n",
      "iteration 16000, Cost: 860.19, bias: [15.95305678], gradient of b: -5.149066358474859e-13\n",
      "iteration 17000, Cost: 860.19, bias: [15.95305678], gradient of b: -5.025905617609775e-13\n",
      "iteration 18000, Cost: 860.19, bias: [15.95305678], gradient of b: -4.893270973601223e-13\n",
      "iteration 19000, Cost: 860.19, bias: [15.95305678], gradient of b: -4.760636329592671e-13\n",
      "iteration 20000, Cost: 860.19, bias: [15.95305678], gradient of b: -4.651686443442789e-13\n",
      "iteration 21000, Cost: 860.19, bias: [15.95305678], gradient of b: -4.54036808150704e-13\n",
      "iteration 22000, Cost: 860.19, bias: [15.95305678], gradient of b: -4.388785631211552e-13\n",
      "iteration 23000, Cost: 860.19, bias: [15.95305678], gradient of b: -4.324836784993143e-13\n",
      "iteration 24000, Cost: 860.19, bias: [15.95305678], gradient of b: -4.246677084059532e-13\n",
      "iteration 25000, Cost: 860.19, bias: [15.95305678], gradient of b: -4.104568536907512e-13\n",
      "iteration 26000, Cost: 860.19, bias: [15.95305678], gradient of b: -4.083252254834709e-13\n",
      "iteration 27000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.97193389289896e-13\n",
      "iteration 28000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.926932852967487e-13\n",
      "iteration 29000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.820351442603472e-13\n",
      "iteration 30000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.799035160530669e-13\n",
      "iteration 31000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.678242895451452e-13\n",
      "iteration 32000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.678242895451452e-13\n",
      "iteration 33000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.623767952376511e-13\n",
      "iteration 34000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.536134348299432e-13\n",
      "iteration 35000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.514818066226629e-13\n",
      "iteration 36000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.443763792650619e-13\n",
      "iteration 37000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.40349970429088e-13\n",
      "iteration 38000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.358498664359407e-13\n",
      "iteration 39000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.251917253995392e-13\n",
      "iteration 40000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.251917253995392e-13\n",
      "iteration 41000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.230600971922589e-13\n",
      "iteration 42000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.187968407776983e-13\n",
      "iteration 43000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.1098087068433717e-13\n",
      "iteration 44000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.1098087068433717e-13\n",
      "iteration 45000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.0932293763423027e-13\n",
      "iteration 46000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.055333763768431e-13\n",
      "iteration 47000, Cost: 860.19, bias: [15.95305678], gradient of b: -3.036385957481495e-13\n",
      "iteration 48000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.9677001596913517e-13\n",
      "iteration 49000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.9677001596913517e-13\n",
      "iteration 50000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.875329604042539e-13\n",
      "iteration 51000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.875329604042539e-13\n",
      "iteration 52000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.875329604042539e-13\n",
      "iteration 53000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.8350655156827996e-13\n",
      "iteration 54000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.8184861851817306e-13\n",
      "iteration 55000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.7900644757513267e-13\n",
      "iteration 56000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.752168863177455e-13\n",
      "iteration 57000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.752168863177455e-13\n",
      "iteration 58000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.6834830653873116e-13\n",
      "iteration 59000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.6834830653873116e-13\n",
      "iteration 60000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.6834830653873116e-13\n",
      "iteration 61000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.662166783314509e-13\n",
      "iteration 62000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.6195342191689027e-13\n",
      "iteration 63000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.6195342191689027e-13\n",
      "iteration 64000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.5413745182352916e-13\n",
      "iteration 65000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.5413745182352916e-13\n",
      "iteration 66000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.5413745182352916e-13\n",
      "iteration 67000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.5413745182352916e-13\n",
      "iteration 68000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.5247951877342225e-13\n",
      "iteration 69000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.4868995751603507e-13\n",
      "iteration 70000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.4868995751603507e-13\n",
      "iteration 71000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.4679517688734147e-13\n",
      "iteration 72000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.3992659710832716e-13\n",
      "iteration 73000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.3992659710832716e-13\n",
      "iteration 74000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.3992659710832716e-13\n",
      "iteration 75000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.3992659710832716e-13\n",
      "iteration 76000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.377949689010469e-13\n",
      "iteration 77000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.3068954154344587e-13\n",
      "iteration 78000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.3068954154344587e-13\n",
      "iteration 79000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.3068954154344587e-13\n",
      "iteration 80000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.3068954154344587e-13\n",
      "iteration 81000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.3068954154344587e-13\n",
      "iteration 82000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.2666313270747195e-13\n",
      "iteration 83000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.2666313270747195e-13\n",
      "iteration 84000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.2666313270747195e-13\n",
      "iteration 85000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.2500519965736507e-13\n",
      "iteration 86000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.2216302871432465e-13\n",
      "iteration 87000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.2216302871432465e-13\n",
      "iteration 88000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.2026824808563106e-13\n",
      "iteration 89000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.2026824808563106e-13\n",
      "iteration 90000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.1150488767792315e-13\n",
      "iteration 91000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.1150488767792315e-13\n",
      "iteration 92000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.1150488767792315e-13\n",
      "iteration 93000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.1150488767792315e-13\n",
      "iteration 94000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.1150488767792315e-13\n",
      "iteration 95000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.1150488767792315e-13\n",
      "iteration 96000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.1150488767792315e-13\n",
      "iteration 97000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.0937325947064284e-13\n",
      "iteration 98000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.0937325947064284e-13\n",
      "iteration 99000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.0511000305608226e-13\n",
      "iteration 100000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.0511000305608226e-13\n",
      "iteration 101000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.0511000305608226e-13\n",
      "iteration 102000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.0511000305608226e-13\n",
      "iteration 103000, Cost: 860.19, bias: [15.95305678], gradient of b: -2.0511000305608226e-13\n",
      "iteration 104000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9729403296272114e-13\n",
      "iteration 105000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9729403296272114e-13\n",
      "iteration 106000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9729403296272114e-13\n",
      "iteration 107000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9729403296272114e-13\n",
      "iteration 108000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9729403296272114e-13\n",
      "iteration 109000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9729403296272114e-13\n",
      "iteration 110000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9729403296272114e-13\n",
      "iteration 111000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9729403296272114e-13\n",
      "iteration 112000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9563609991261426e-13\n",
      "iteration 113000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9563609991261426e-13\n",
      "iteration 114000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9184653865522705e-13\n",
      "iteration 115000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9184653865522705e-13\n",
      "iteration 116000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9184653865522705e-13\n",
      "iteration 117000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.9184653865522705e-13\n",
      "iteration 118000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8995175802653346e-13\n",
      "iteration 119000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8995175802653346e-13\n",
      "iteration 120000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8995175802653346e-13\n",
      "iteration 121000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8308317824751914e-13\n",
      "iteration 122000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8308317824751914e-13\n",
      "iteration 123000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8308317824751914e-13\n",
      "iteration 124000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8308317824751914e-13\n",
      "iteration 125000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8308317824751914e-13\n",
      "iteration 126000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8308317824751914e-13\n",
      "iteration 127000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8308317824751914e-13\n",
      "iteration 128000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8308317824751914e-13\n",
      "iteration 129000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8308317824751914e-13\n",
      "iteration 130000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8095155004023884e-13\n",
      "iteration 131000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8095155004023884e-13\n",
      "iteration 132000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.8095155004023884e-13\n",
      "iteration 133000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.7384612268263783e-13\n",
      "iteration 134000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.7384612268263783e-13\n",
      "iteration 135000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.7384612268263783e-13\n",
      "iteration 136000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.7384612268263783e-13\n",
      "iteration 137000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.7384612268263783e-13\n",
      "iteration 138000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.7384612268263783e-13\n",
      "iteration 139000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.7384612268263783e-13\n",
      "iteration 140000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.7384612268263783e-13\n",
      "iteration 141000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.7384612268263783e-13\n",
      "iteration 142000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.7384612268263783e-13\n",
      "iteration 143000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.7384612268263783e-13\n",
      "iteration 144000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6981971384666393e-13\n",
      "iteration 145000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6981971384666393e-13\n",
      "iteration 146000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6981971384666393e-13\n",
      "iteration 147000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6981971384666393e-13\n",
      "iteration 148000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6981971384666393e-13\n",
      "iteration 149000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6981971384666393e-13\n",
      "iteration 150000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6981971384666393e-13\n",
      "iteration 151000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6816178079655705e-13\n",
      "iteration 152000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6816178079655705e-13\n",
      "iteration 153000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6816178079655705e-13\n",
      "iteration 154000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6531960985351664e-13\n",
      "iteration 155000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6531960985351664e-13\n",
      "iteration 156000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6531960985351664e-13\n",
      "iteration 157000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6531960985351664e-13\n",
      "iteration 158000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6531960985351664e-13\n",
      "iteration 159000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6153004859612945e-13\n",
      "iteration 160000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6153004859612945e-13\n",
      "iteration 161000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6153004859612945e-13\n",
      "iteration 162000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6153004859612945e-13\n",
      "iteration 163000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6153004859612945e-13\n",
      "iteration 164000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6153004859612945e-13\n",
      "iteration 165000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6153004859612945e-13\n",
      "iteration 166000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.6153004859612945e-13\n",
      "iteration 167000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 168000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 169000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 170000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 171000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 172000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 173000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 174000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 175000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 176000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 177000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 178000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 179000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 180000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 181000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5466146881711513e-13\n",
      "iteration 182000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5252984060983483e-13\n",
      "iteration 183000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5252984060983483e-13\n",
      "iteration 184000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5252984060983483e-13\n",
      "iteration 185000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5252984060983483e-13\n",
      "iteration 186000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.5252984060983483e-13\n",
      "iteration 187000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4826658419527424e-13\n",
      "iteration 188000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4826658419527424e-13\n",
      "iteration 189000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4826658419527424e-13\n",
      "iteration 190000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4826658419527424e-13\n",
      "iteration 191000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4826658419527424e-13\n",
      "iteration 192000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4826658419527424e-13\n",
      "iteration 193000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4826658419527424e-13\n",
      "iteration 194000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4826658419527424e-13\n",
      "iteration 195000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4826658419527424e-13\n",
      "iteration 196000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4826658419527424e-13\n",
      "iteration 197000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4826658419527424e-13\n",
      "iteration 198000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 199000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 200000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 201000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 202000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 203000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 204000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 205000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 206000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 207000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 208000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 209000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 210000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 211000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 212000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 213000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 214000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 215000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 216000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 217000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 218000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 219000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.4045061410191313e-13\n",
      "iteration 220000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3879268105180625e-13\n",
      "iteration 221000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3879268105180625e-13\n",
      "iteration 222000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3879268105180625e-13\n",
      "iteration 223000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3879268105180625e-13\n",
      "iteration 224000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3879268105180625e-13\n",
      "iteration 225000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3879268105180625e-13\n",
      "iteration 226000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3500311979441904e-13\n",
      "iteration 227000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3500311979441904e-13\n",
      "iteration 228000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3500311979441904e-13\n",
      "iteration 229000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3500311979441904e-13\n",
      "iteration 230000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3500311979441904e-13\n",
      "iteration 231000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3500311979441904e-13\n",
      "iteration 232000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3500311979441904e-13\n",
      "iteration 233000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3500311979441904e-13\n",
      "iteration 234000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3500311979441904e-13\n",
      "iteration 235000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3500311979441904e-13\n",
      "iteration 236000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3500311979441904e-13\n",
      "iteration 237000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3500311979441904e-13\n",
      "iteration 238000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3310833916572544e-13\n",
      "iteration 239000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3310833916572544e-13\n",
      "iteration 240000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3310833916572544e-13\n",
      "iteration 241000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3310833916572544e-13\n",
      "iteration 242000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3310833916572544e-13\n",
      "iteration 243000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3310833916572544e-13\n",
      "iteration 244000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.3310833916572544e-13\n",
      "iteration 245000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 246000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 247000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 248000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 249000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 250000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 251000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 252000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 253000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 254000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 255000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 256000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 257000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 258000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 259000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 260000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 261000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 262000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 263000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 264000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 265000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 266000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 267000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 268000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 269000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 270000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 271000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 272000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2623975938671113e-13\n",
      "iteration 273000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2600291180812444e-13\n",
      "iteration 274000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2410813117943082e-13\n",
      "iteration 275000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2410813117943082e-13\n",
      "iteration 276000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2410813117943082e-13\n",
      "iteration 277000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2410813117943082e-13\n",
      "iteration 278000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2410813117943082e-13\n",
      "iteration 279000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2410813117943082e-13\n",
      "iteration 280000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2410813117943082e-13\n",
      "iteration 281000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.2410813117943082e-13\n",
      "iteration 282000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 283000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 284000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 285000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 286000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 287000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 288000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 289000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 290000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 291000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 292000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 293000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 294000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 295000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 296000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 297000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 298000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 299000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 300000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 301000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 302000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 303000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 304000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 305000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 306000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 307000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 308000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 309000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 310000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 311000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 312000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 313000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 314000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 315000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 316000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1700270382182982e-13\n",
      "iteration 317000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 318000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 319000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 320000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 321000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 322000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 323000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 324000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 325000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 326000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 327000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 328000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 329000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 330000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 331000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 332000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 333000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 334000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 335000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 336000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 337000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 338000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 339000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1297629498585593e-13\n",
      "iteration 340000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1131836193574902e-13\n",
      "iteration 341000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1131836193574902e-13\n",
      "iteration 342000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1131836193574902e-13\n",
      "iteration 343000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1131836193574902e-13\n",
      "iteration 344000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1131836193574902e-13\n",
      "iteration 345000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1131836193574902e-13\n",
      "iteration 346000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1131836193574902e-13\n",
      "iteration 347000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1131836193574902e-13\n",
      "iteration 348000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1131836193574902e-13\n",
      "iteration 349000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.1131836193574902e-13\n",
      "iteration 350000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 351000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 352000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 353000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 354000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 355000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 356000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 357000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 358000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 359000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 360000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 361000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 362000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 363000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 364000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 365000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 366000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 367000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 368000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0847619099270863e-13\n",
      "iteration 369000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 370000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 371000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 372000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 373000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 374000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 375000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 376000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 377000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 378000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 379000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 380000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 381000, Cost: 860.19, bias: [15.95305678], gradient of b: -1.0658141036401503e-13\n",
      "iteration 382000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 383000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 384000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 385000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 386000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 387000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 388000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 389000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 390000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 391000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 392000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 393000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 394000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 395000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 396000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 397000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 398000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 399000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 400000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 401000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 402000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 403000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 404000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 405000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 406000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 407000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 408000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 409000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n",
      "iteration 410000, Cost: 860.19, bias: [15.95305678], gradient of b: -9.781804995630713e-14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m*\u001b[39m x_train_np \u001b[38;5;241m+\u001b[39m b\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate the cost using Mean Squared Error (MSE)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m cost \u001b[38;5;241m=\u001b[39m mean_squared_error(y_train, y_pred)\n\u001b[0;32m     15\u001b[0m t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Show the cost every 1000 iterations\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicet\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nicet\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[1;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    507\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\nicet\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:111\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m--> 111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\nicet\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:455\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03mChecks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m>>> check_consistent_length(a, b)\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m--> 455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nicet\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:276\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[38;5;241m=\u001b[39mequal_nan)\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nicet\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:125\u001b[0m, in \u001b[0;36m_unpack_tuple\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    121\u001b[0m     np\u001b[38;5;241m.\u001b[39msubtract(ary[\u001b[38;5;241m1\u001b[39m:], ary[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], result[l_begin:l_begin \u001b[38;5;241m+\u001b[39m l_diff])\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unpack_tuple\u001b[39m(x):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Unpacks one-element tuples for use as return values \"\"\"\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dB_SS = 0\n",
    "t = 0\n",
    "for i in range(epochs*10000):\n",
    "    # Calculate the gradient of b\n",
    "    dB = 2 * ((w * x_train_np + b - y_train_np)).mean()\n",
    "    # Update the mean square value of the gradient of b\n",
    "    dB_SS += dB**2\n",
    "    dB_RMS = np.sqrt(dB_SS / (t + 1))\n",
    "    # Update the bias\n",
    "    b -= learning_rate * dB / dB_RMS\n",
    "    # Recalculate y_pred after updating bias\n",
    "    y_pred = w * x_train_np + b\n",
    "    # Calculate the cost using Mean Squared Error (MSE)\n",
    "    cost = mean_squared_error(y_train, y_pred)\n",
    "    t += 1\n",
    "    # Show the cost every 1000 iterations\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"iteration {i}, Cost: {cost:.2f}, bias: {b}, gradient of b: {dB}\")\n",
    "# Show the final weights and bias\n",
    "print(\"Final Weights: \", w)\n",
    "print(\"Final Bias: \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.  After 1 million time of iteration, Both b and w becomes a complete new value. The next thing I would like to do is to show the relationship of the trend line using data predicted by my model with the actual training data. This can be done with the help with the matplotlib package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training data and trend line\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.scatter(x_train, y_train, color='b', label='GDP Growth Rate vs Unemployment Rate')\n",
    "plt.plot(x_train, y_pred, color='r', label='Trend Line')\n",
    "plt.title('GDP Growth Rate vs Unemployment Rate')\n",
    "plt.xlabel('GDP Growth Rate')\n",
    "plt.ylabel('Unemployment Rate')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. However, this step only proves how well the data fits the training data. To evualate the accuracy of the model, we need to test it with the test data, which it hasn't been trained on the whole time. Also, I will plot the graph below to visualize the performance of the model with mataplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real % change in Unemployment Rate: -12.50, Predicted % change in Unemployment Rate: 3.92\n",
      "Real % change in Unemployment Rate: -39.29, Predicted % change in Unemployment Rate: -21.55\n",
      "Real % change in Unemployment Rate: -9.68, Predicted % change in Unemployment Rate: 8.12\n",
      "Real % change in Unemployment Rate: 31.91, Predicted % change in Unemployment Rate: 8.96\n",
      "Real % change in Unemployment Rate: -20.97, Predicted % change in Unemployment Rate: -5.59\n",
      "Real % change in Unemployment Rate: -8.82, Predicted % change in Unemployment Rate: 5.32\n",
      "Real % change in Unemployment Rate: 8.22, Predicted % change in Unemployment Rate: 7.28\n",
      "Real % change in Unemployment Rate: -2.94, Predicted % change in Unemployment Rate: 8.12\n",
      "cost:  248.44936253622524\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 3.8 Data Evaluation: Evaluate the model using the testing data\n",
    "y_test_pred = w * x_test + b\n",
    "# Show the original output alongside the predicted output\n",
    "for pred, actual in zip(y_test_pred, y_test):\n",
    "    print(f\"Real % change in Unemployment Rate: {actual:.2f}, Predicted % change in Unemployment Rate: {pred:.2f}\")\n",
    "# Task 3.8 Data Evaluation: Calculate the cost using Mean Squared Error (MSE)\n",
    "cost = mean_squared_error(y_test, y_test_pred)\n",
    "# Show the cost\n",
    "print(\"cost: \", cost)\n",
    "# Task 3.8 Data Evaluation: Plot the testing data and trend line\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.scatter(x_test, y_test, color='b', label='GDP Growth Rate vs Unemployment Rate')\n",
    "plt.plot(x_test, y_test_pred, color='r', label='Trend Line')\n",
    "plt.title('GDP Growth Rate vs % change in Unemployment Rate')\n",
    "plt.xlabel('GDP Growth Rate')\n",
    "plt.ylabel('% change in Unemployment Rate')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. In summary, after gradient descent, our model reduced the cost from 1352.2099273717338 (initial state predicting training data) to 175.1687211891239 (tuned state predicting test data) when predicting the data sets it has not yet been trained on. It means that our model has a significent increase of accuracy. The final step I am going to perform is making this model usable for other users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted unemployment rate (%) is: 17.96\n",
      "The cost is: 527.06\n",
      "WARNING: THE COST IS TOO HIGH,  THE DATA WITH CAUTION\n"
     ]
    }
   ],
   "source": [
    "# Save the w and b value into a final state avoiding overwriting the previous w and b value\n",
    "w_final = w\n",
    "b_final = b\n",
    "# Perform a asking for user to input a GDP growth rate and predict the unemployment rate using the final weights and bias\n",
    "gdp_growth_rate = float(input(\"Please enter the GDP growth rate (%): \"))\n",
    "Previous_Unemployment_Rate = float(input(\"Please enter the previous unemployment rate (%): \"))\n",
    "# Check if the input is valid (between -100 and 100)\n",
    "if gdp_growth_rate < -100 or gdp_growth_rate > 100:\n",
    "    print(\"Invalid input. Please enter a value between -100 and 100.\")\n",
    "    exit(1)\n",
    "# Check if the input is valid (between -100 and 100)\n",
    "if Previous_Unemployment_Rate < -100 or Previous_Unemployment_Rate > 100:\n",
    "    print(\"Invalid input. Please enter a value between -100 and 100.\")\n",
    "    exit(1)\n",
    "# Predict the % change in unemployment rate using the final weights and bias\n",
    "P_change_in_unemployment_rate = w_final * gdp_growth_rate + b_final\n",
    "# Predict the unemployment rate using P_change_in_unemployment_rate and Previous_Unemployment_Rate\n",
    "unemployment_rate = Previous_Unemployment_Rate + P_change_in_unemployment_rate\n",
    "# Extract the scalar value from the NumPy array\n",
    "unemployment_rate_scalar = unemployment_rate.item()\n",
    "# Show the predicted unemployment rate\n",
    "print(f\"The predicted unemployment rate (%) is: {unemployment_rate_scalar:.2f}\")\n",
    "# To see if the gdp data appears in the original data we collected, if yes we can calculate the cost and print it out\n",
    "# Check if the gdp growth rate is in the original data\n",
    "if gdp_growth_rate in x.values:\n",
    "    # Get the index of the gdp growth rate in the original data\n",
    "    GDP_Growth_index = x.index[x == gdp_growth_rate][0]\n",
    "    # Get the unemployment rate from the original data\n",
    "    P_change_unemployment_rate_original = y[GDP_Growth_index]\n",
    "    # Calculate the cost using Mean Squared Error (MSE)\n",
    "    cost_check = mean_squared_error([P_change_unemployment_rate_original], [P_change_in_unemployment_rate])\n",
    "    # Show the cost\n",
    "    print(f\"The cost is: {cost_check:.2f}\")\n",
    "if cost_check > 200:\n",
    "    print(\"WARNING: THE COST IS TOO HIGH,  THE DATA WITH CAUTION\")\n",
    "else:\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflections: you may have noticed that the slope and intercept (i.e. w and b) of my trend line differs with the one in eccel. There are many possible reasons for that, including insufficient rounds of gradient descent (i.e. iteration), improper setting of learning rate, or even the missing x value in training (i.e. the test data) counts a significent role in computing gradients. Addressing these issues, we may increase the iteration, vary the initial learning rate, and change the testing set with another random seed. Below is the cost of data if using the slope and intercept in excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real % change in Unemployment Rate: -12.50, Predicted % change in Unemployment Rate: -0.11\n",
      "Real % change in Unemployment Rate: -39.29, Predicted % change in Unemployment Rate: -51.24\n",
      "Real % change in Unemployment Rate: -9.68, Predicted % change in Unemployment Rate: 8.32\n",
      "Real % change in Unemployment Rate: 31.91, Predicted % change in Unemployment Rate: 10.01\n",
      "Real % change in Unemployment Rate: -20.97, Predicted % change in Unemployment Rate: -19.21\n",
      "Real % change in Unemployment Rate: -8.82, Predicted % change in Unemployment Rate: 2.70\n",
      "Real % change in Unemployment Rate: 8.22, Predicted % change in Unemployment Rate: 6.64\n",
      "Real % change in Unemployment Rate: -2.94, Predicted % change in Unemployment Rate: 8.32\n",
      "cost:  170.72818206130933\n"
     ]
    }
   ],
   "source": [
    "w_excel = -5.619417892\n",
    "b_excel = 24.05770388\n",
    "# Predict the test data using the regressioned weights and bias.\n",
    "y_test_pred_excel = w_excel * x_test + b_excel\n",
    "# Show the original output alongside the predicted output\n",
    "for pred, actual in zip(y_test_pred_excel, y_test):\n",
    "    print(f\"Real % change in Unemployment Rate: {actual:.2f}, Predicted % change in Unemployment Rate: {pred:.2f}\")\n",
    "# Calculate the cost using Mean Squared Error (MSE)\n",
    "cost = mean_squared_error(y_test, y_test_pred_excel)\n",
    "# Show the cost\n",
    "print(\"cost: \", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As result, the cost of regression predict line (170.72818206130933) is lower than the cost of my model (248.44936253622524). One possible reason for that is the rough cost function of our model created a local minimum point above the global minimum point. When our model adjusted to the local minimum point, the gradient becomes 0, and the gradient descent process stopped, causing our model stucked at the local minimum instead of global minimum. The other reason for that will be insufficient iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, Cost: 1148.23 Weight:  [-1.23482477] gradient of w:  153.1073929215773\n",
      "iteration 1000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 2000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 3000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 4000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 5000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 6000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 7000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 8000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 9000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 10000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 11000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 12000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 13000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 14000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 15000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 16000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 17000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 18000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 19000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 20000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 21000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 22000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 23000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 24000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 25000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 26000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 27000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 28000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 29000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 30000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 31000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 32000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 33000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 34000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 35000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 36000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 37000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 38000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 39000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 40000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 41000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 42000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 43000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 44000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 45000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 46000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 47000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 48000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 49000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 50000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 51000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 52000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 53000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 54000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 55000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 56000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 57000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 58000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 59000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 60000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 61000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 62000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 63000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 64000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 65000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 66000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 67000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 68000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 69000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 70000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 71000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 72000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 73000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 74000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 75000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 76000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 77000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 78000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 79000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 80000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 81000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 82000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 83000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 84000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 85000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 86000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 87000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 88000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 89000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 90000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 91000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 92000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 93000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 94000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 95000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 96000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 97000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 98000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 99000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 100000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 101000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 102000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 103000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 104000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 105000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 106000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 107000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 108000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 109000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 110000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 111000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 112000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 113000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 114000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 115000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 116000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 117000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 118000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 119000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 120000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 121000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 122000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 123000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 124000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 125000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 126000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 127000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 128000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 129000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 130000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 131000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 132000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 133000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 134000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 135000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 136000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 137000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 138000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 139000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 140000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 141000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 142000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 143000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 144000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 145000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 146000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 147000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 148000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 149000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 150000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 151000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 152000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 153000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 154000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 155000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 156000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 157000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 158000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 159000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 160000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 161000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 162000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 163000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 164000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 165000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 166000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 167000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 168000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 169000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 170000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 171000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 172000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 173000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 174000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 175000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 176000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 177000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 178000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 179000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 180000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 181000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 182000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 183000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 184000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 185000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 186000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 187000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 188000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 189000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 190000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 191000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 192000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 193000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 194000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 195000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 196000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 197000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 198000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 199000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 200000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 201000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 202000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 203000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 204000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 205000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 206000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 207000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 208000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 209000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 210000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 211000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 212000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 213000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 214000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 215000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 216000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 217000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 218000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 219000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 220000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 221000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 222000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 223000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 224000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 225000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 226000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 227000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 228000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 229000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 230000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 231000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 232000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 233000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 234000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 235000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 236000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 237000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 238000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 239000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 240000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 241000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 242000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 243000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 244000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 245000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 246000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 247000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 248000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 249000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 250000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 251000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 252000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 253000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 254000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 255000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 256000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 257000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 258000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 259000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 260000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 261000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 262000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 263000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 264000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 265000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 266000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 267000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 268000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 269000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 270000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 271000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 272000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 273000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 274000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 275000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 276000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 277000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 278000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 279000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 280000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 281000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 282000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 283000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 284000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 285000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 286000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 287000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 288000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 289000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 290000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 291000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 292000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 293000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 294000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 295000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 296000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 297000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 298000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 299000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 300000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 301000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 302000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 303000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 304000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 305000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 306000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 307000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 308000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 309000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 310000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 311000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 312000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 313000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 314000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 315000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 316000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 317000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 318000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 319000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 320000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 321000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 322000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 323000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 324000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 325000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 326000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 327000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 328000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 329000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 330000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 331000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 332000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 333000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 334000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 335000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 336000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 337000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 338000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 339000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 340000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 341000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 342000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 343000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 344000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 345000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 346000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 347000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 348000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 349000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 350000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 351000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 352000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 353000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 354000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 355000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 356000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 357000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 358000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 359000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 360000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 361000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 362000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 363000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 364000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 365000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 366000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 367000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 368000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 369000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 370000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 371000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 372000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 373000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 374000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 375000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 376000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 377000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 378000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 379000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 380000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 381000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 382000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 383000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 384000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 385000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 386000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 387000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 388000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 389000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 390000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 391000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 392000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 393000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 394000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 395000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 396000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 397000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 398000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 399000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 400000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 401000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 402000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 403000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 404000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 405000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 406000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 407000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 408000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 409000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 410000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 411000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 412000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 413000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 414000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 415000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 416000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 417000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 418000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 419000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 420000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 421000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 422000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 423000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 424000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 425000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 426000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 427000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 428000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 429000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 430000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 431000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 432000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 433000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 434000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 435000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 436000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 437000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 438000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 439000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 440000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 441000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 442000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 443000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 444000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 445000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 446000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 447000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 448000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 449000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 450000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 451000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 452000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 453000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 454000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 455000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 456000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 457000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 458000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 459000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 460000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 461000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 462000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 463000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 464000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 465000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 466000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 467000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 468000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 469000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 470000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 471000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 472000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 473000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 474000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 475000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 476000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 477000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 478000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 479000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 480000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 481000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 482000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 483000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 484000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 485000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 486000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 487000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 488000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 489000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 490000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 491000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 492000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 493000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 494000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 495000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 496000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 497000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 498000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 499000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 500000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 501000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 502000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 503000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 504000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 505000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 506000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 507000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 508000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 509000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 510000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 511000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 512000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 513000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 514000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 515000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 516000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 517000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 518000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 519000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 520000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 521000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 522000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 523000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 524000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 525000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 526000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 527000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 528000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 529000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 530000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 531000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 532000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 533000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 534000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 535000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 536000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 537000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 538000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 539000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 540000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 541000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 542000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 543000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 544000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 545000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 546000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 547000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 548000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 549000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 550000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 551000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 552000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 553000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 554000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 555000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 556000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 557000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 558000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 559000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 560000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 561000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 562000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 563000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 564000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 565000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 566000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 567000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 568000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 569000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 570000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 571000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 572000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 573000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 574000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 575000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 576000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 577000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 578000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 579000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 580000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 581000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 582000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 583000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 584000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 585000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 586000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 587000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 588000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 589000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 590000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 591000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 592000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 593000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 594000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 595000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 596000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 597000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 598000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 599000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 600000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 601000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 602000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 603000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 604000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 605000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 606000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 607000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 608000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 609000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 610000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 611000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 612000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 613000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 614000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 615000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 616000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 617000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 618000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 619000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 620000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 621000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 622000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 623000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 624000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 625000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 626000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 627000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 628000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 629000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 630000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 631000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 632000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 633000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 634000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 635000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 636000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 637000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 638000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 639000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 640000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 641000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 642000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 643000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 644000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 645000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 646000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 647000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 648000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 649000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 650000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 651000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 652000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 653000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 654000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 655000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 656000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 657000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 658000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 659000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 660000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 661000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 662000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 663000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 664000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 665000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 666000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 667000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 668000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 669000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 670000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 671000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 672000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 673000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 674000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 675000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 676000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 677000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 678000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 679000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 680000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 681000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 682000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 683000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 684000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 685000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 686000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 687000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 688000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 689000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 690000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 691000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 692000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 693000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 694000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 695000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 696000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 697000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 698000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 699000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 700000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 701000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 702000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 703000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 704000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 705000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 706000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 707000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 708000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 709000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 710000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 711000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 712000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 713000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 714000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 715000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 716000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 717000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 718000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 719000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 720000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 721000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 722000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 723000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 724000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 725000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 726000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 727000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 728000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 729000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 730000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 731000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 732000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 733000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 734000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 735000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 736000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 737000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 738000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 739000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 740000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 741000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 742000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 743000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 744000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 745000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 746000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 747000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 748000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 749000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 750000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 751000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 752000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 753000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 754000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 755000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 756000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 757000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 758000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 759000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 760000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 761000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 762000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 763000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 764000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 765000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 766000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 767000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 768000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 769000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 770000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 771000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 772000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 773000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 774000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 775000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 776000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 777000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 778000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 779000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 780000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 781000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 782000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 783000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 784000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 785000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 786000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 787000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 788000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 789000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 790000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 791000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 792000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 793000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 794000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 795000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 796000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 797000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 798000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 799000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 800000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 801000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 802000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 803000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 804000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 805000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 806000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 807000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 808000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 809000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 810000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 811000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 812000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 813000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 814000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 815000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 816000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 817000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 818000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 819000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 820000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 821000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 822000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 823000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 824000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 825000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 826000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 827000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 828000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 829000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 830000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 831000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 832000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 833000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 834000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 835000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 836000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 837000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 838000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 839000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 840000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 841000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 842000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 843000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 844000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 845000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 846000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 847000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 848000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 849000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 850000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 851000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 852000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 853000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 854000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 855000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 856000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 857000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 858000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 859000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 860000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 861000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 862000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 863000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 864000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 865000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 866000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 867000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 868000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 869000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 870000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 871000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 872000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 873000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 874000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 875000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 876000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 877000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 878000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 879000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 880000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 881000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 882000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 883000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 884000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 885000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 886000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 887000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 888000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 889000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 890000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 891000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 892000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 893000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 894000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 895000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 896000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 897000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 898000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 899000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 900000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 901000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 902000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 903000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 904000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 905000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 906000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 907000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 908000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 909000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 910000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 911000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 912000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 913000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 914000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 915000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 916000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 917000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 918000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 919000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 920000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 921000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 922000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 923000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 924000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 925000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 926000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 927000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 928000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 929000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 930000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 931000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 932000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 933000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 934000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 935000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 936000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 937000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 938000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 939000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 940000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 941000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 942000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 943000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 944000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 945000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 946000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 947000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 948000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 949000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 950000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 951000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 952000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 953000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 954000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 955000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 956000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 957000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 958000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 959000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 960000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 961000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 962000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 963000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 964000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 965000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 966000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 967000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 968000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 969000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 970000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 971000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 972000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 973000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 974000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 975000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 976000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 977000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 978000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 979000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 980000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 981000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 982000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 983000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 984000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 985000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 986000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 987000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 988000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 989000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 990000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 991000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 992000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 993000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 994000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 995000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 996000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 997000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 998000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 999000, Cost: 1089.51 Weight:  [-2.76798237] gradient of w:  1.8000415972589204e-14\n",
      "iteration 0, Cost: 1080.54 Bias:  [1.11006045] gradient of b:  -30.099273062876446\n",
      "iteration 1000, Cost: 863.02 Bias:  [15.85870422] gradient of b:  -5.0656097035547036e-08\n",
      "iteration 2000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 3000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 4000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 5000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 6000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 7000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 8000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 9000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 10000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 11000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 12000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 13000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 14000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 15000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 16000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 17000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 18000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 19000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 20000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 21000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 22000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 23000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 24000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 25000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 26000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 27000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 28000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 29000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 30000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 31000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 32000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 33000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 34000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 35000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 36000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 37000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 38000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 39000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 40000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 41000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 42000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 43000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 44000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 45000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 46000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 47000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 48000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 49000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 50000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 51000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 52000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 53000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 54000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 55000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 56000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 57000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 58000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 59000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 60000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 61000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 62000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 63000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 64000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 65000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 66000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 67000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 68000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 69000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 70000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 71000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 72000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 73000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 74000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 75000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 76000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 77000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 78000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 79000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 80000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 81000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 82000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 83000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 84000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 85000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 86000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 87000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 88000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 89000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 90000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 91000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 92000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 93000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 94000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 95000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 96000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 97000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 98000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 99000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 100000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 101000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 102000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 103000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 104000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 105000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 106000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 107000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 108000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 109000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 110000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 111000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 112000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 113000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 114000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 115000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 116000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 117000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 118000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 119000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 120000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 121000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 122000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 123000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 124000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 125000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 126000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 127000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 128000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 129000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 130000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 131000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 132000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 133000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 134000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 135000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 136000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 137000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 138000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 139000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 140000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 141000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 142000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 143000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 144000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 145000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 146000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 147000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 148000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 149000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 150000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 151000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 152000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 153000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 154000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 155000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 156000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 157000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 158000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 159000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 160000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 161000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 162000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 163000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 164000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 165000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 166000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 167000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 168000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 169000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 170000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 171000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 172000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 173000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 174000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 175000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 176000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 177000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 178000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 179000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 180000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 181000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 182000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 183000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 184000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 185000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 186000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 187000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 188000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 189000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 190000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 191000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 192000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 193000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 194000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 195000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 196000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 197000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 198000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 199000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 200000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 201000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 202000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 203000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 204000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 205000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 206000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 207000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 208000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 209000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 210000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 211000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 212000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 213000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 214000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 215000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 216000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 217000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 218000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 219000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 220000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 221000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 222000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 223000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 224000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 225000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 226000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 227000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 228000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 229000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 230000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 231000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 232000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 233000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 234000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 235000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 236000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 237000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 238000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 239000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 240000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 241000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 242000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 243000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 244000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 245000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 246000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 247000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 248000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 249000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 250000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 251000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 252000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 253000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 254000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 255000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 256000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 257000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 258000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 259000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 260000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 261000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 262000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 263000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 264000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 265000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 266000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 267000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 268000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 269000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 270000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 271000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 272000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 273000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 274000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 275000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 276000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 277000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 278000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 279000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 280000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 281000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 282000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 283000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 284000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 285000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 286000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 287000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 288000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 289000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 290000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 291000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 292000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 293000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 294000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 295000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 296000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 297000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 298000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 299000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 300000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 301000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 302000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 303000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 304000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 305000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 306000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 307000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 308000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 309000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 310000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 311000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 312000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 313000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 314000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 315000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 316000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 317000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 318000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 319000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 320000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 321000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 322000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 323000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 324000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 325000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 326000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 327000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 328000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 329000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 330000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 331000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 332000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 333000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 334000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 335000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 336000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 337000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 338000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 339000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 340000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 341000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 342000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 343000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 344000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 345000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 346000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 347000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 348000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 349000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 350000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 351000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 352000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 353000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 354000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 355000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 356000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 357000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 358000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 359000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 360000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 361000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 362000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 363000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 364000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 365000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 366000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 367000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 368000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 369000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 370000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 371000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 372000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 373000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 374000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 375000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 376000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 377000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 378000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 379000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 380000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 381000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 382000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 383000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 384000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 385000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 386000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 387000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 388000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 389000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 390000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 391000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 392000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 393000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 394000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 395000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 396000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 397000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 398000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 399000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 400000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 401000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 402000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 403000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 404000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 405000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 406000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 407000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 408000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 409000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 410000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 411000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 412000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 413000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 414000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 415000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 416000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 417000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 418000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 419000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 420000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 421000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 422000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 423000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 424000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 425000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 426000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 427000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 428000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 429000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 430000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 431000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 432000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 433000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 434000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 435000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 436000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 437000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 438000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 439000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 440000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 441000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 442000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 443000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 444000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 445000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 446000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 447000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 448000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 449000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 450000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 451000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 452000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 453000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 454000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 455000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 456000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 457000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 458000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 459000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 460000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 461000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 462000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 463000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 464000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 465000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 466000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 467000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 468000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 469000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 470000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 471000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 472000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 473000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 474000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 475000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 476000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 477000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 478000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 479000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 480000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 481000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 482000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 483000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 484000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 485000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 486000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 487000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 488000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 489000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 490000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 491000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 492000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 493000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 494000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 495000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 496000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 497000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 498000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 499000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 500000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 501000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 502000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 503000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 504000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 505000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 506000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 507000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 508000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 509000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 510000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 511000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 512000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 513000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 514000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 515000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 516000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 517000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 518000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 519000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 520000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 521000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 522000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 523000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 524000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 525000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 526000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 527000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 528000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 529000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 530000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 531000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 532000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 533000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 534000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 535000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 536000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 537000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 538000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 539000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 540000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 541000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 542000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 543000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 544000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 545000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 546000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 547000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 548000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 549000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 550000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 551000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 552000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 553000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 554000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 555000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 556000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 557000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 558000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 559000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 560000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 561000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 562000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 563000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 564000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 565000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 566000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 567000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 568000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 569000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 570000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 571000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 572000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 573000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 574000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 575000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 576000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 577000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 578000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 579000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 580000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 581000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 582000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 583000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 584000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 585000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 586000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 587000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 588000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 589000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 590000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 591000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 592000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 593000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 594000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 595000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 596000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 597000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 598000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 599000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 600000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 601000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 602000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 603000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 604000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 605000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 606000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 607000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 608000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 609000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 610000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 611000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 612000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 613000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 614000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 615000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 616000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 617000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 618000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 619000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 620000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 621000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 622000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 623000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 624000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 625000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 626000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 627000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 628000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 629000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 630000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 631000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 632000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 633000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 634000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 635000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 636000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 637000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 638000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 639000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 640000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 641000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 642000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 643000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 644000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 645000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 646000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 647000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 648000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 649000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 650000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 651000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 652000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 653000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 654000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 655000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 656000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 657000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 658000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 659000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 660000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 661000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 662000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 663000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 664000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 665000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 666000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 667000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 668000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 669000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 670000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 671000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 672000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 673000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 674000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 675000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 676000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 677000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 678000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 679000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 680000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 681000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 682000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 683000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 684000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 685000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 686000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 687000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 688000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 689000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 690000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 691000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 692000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 693000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 694000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 695000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 696000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 697000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 698000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 699000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 700000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 701000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 702000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 703000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 704000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 705000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 706000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 707000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 708000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 709000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 710000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 711000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 712000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 713000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 714000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 715000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 716000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 717000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 718000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 719000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 720000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 721000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 722000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 723000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 724000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 725000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 726000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 727000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 728000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 729000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 730000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 731000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 732000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 733000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 734000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 735000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 736000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 737000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 738000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 739000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 740000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 741000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 742000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 743000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 744000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 745000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 746000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 747000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 748000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 749000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 750000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 751000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 752000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 753000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 754000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 755000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 756000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 757000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 758000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 759000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 760000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 761000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 762000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 763000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 764000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 765000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 766000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 767000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 768000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 769000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 770000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 771000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 772000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 773000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 774000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 775000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 776000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 777000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 778000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 779000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 780000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 781000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 782000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 783000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 784000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 785000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 786000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 787000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 788000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 789000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 790000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 791000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 792000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 793000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 794000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 795000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 796000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 797000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 798000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 799000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 800000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 801000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 802000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 803000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 804000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 805000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 806000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 807000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 808000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 809000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 810000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 811000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 812000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 813000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 814000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 815000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 816000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 817000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 818000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 819000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 820000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 821000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 822000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 823000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 824000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 825000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 826000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 827000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 828000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 829000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 830000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 831000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 832000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 833000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 834000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 835000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 836000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 837000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 838000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 839000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 840000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 841000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 842000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 843000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 844000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 845000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 846000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 847000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 848000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 849000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 850000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 851000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 852000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 853000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 854000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 855000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 856000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 857000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 858000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 859000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 860000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 861000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 862000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 863000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 864000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 865000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 866000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 867000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 868000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 869000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 870000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 871000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 872000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 873000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 874000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 875000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 876000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 877000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 878000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 879000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 880000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 881000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 882000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 883000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 884000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 885000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 886000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 887000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 888000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 889000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 890000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 891000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 892000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 893000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 894000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 895000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 896000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 897000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 898000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 899000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 900000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 901000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 902000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 903000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 904000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 905000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 906000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 907000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 908000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 909000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 910000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 911000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 912000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 913000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 914000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 915000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 916000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 917000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 918000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 919000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 920000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 921000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 922000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 923000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 924000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 925000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 926000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 927000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 928000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 929000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 930000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 931000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 932000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 933000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 934000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 935000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 936000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 937000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 938000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 939000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 940000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 941000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 942000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 943000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 944000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 945000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 946000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 947000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 948000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 949000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 950000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 951000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 952000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 953000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 954000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 955000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 956000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 957000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 958000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 959000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 960000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 961000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 962000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 963000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 964000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 965000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 966000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 967000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 968000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 969000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 970000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 971000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 972000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 973000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 974000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 975000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 976000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 977000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 978000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 979000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 980000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 981000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 982000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 983000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 984000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 985000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 986000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 987000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 988000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 989000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 990000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 991000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 992000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 993000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 994000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 995000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 996000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 997000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 998000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "iteration 999000, Cost: 863.02 Bias:  [15.85870425] gradient of b:  -8.455458555545192e-14\n",
      "Cost on test data:  250.65291767685522\n"
     ]
    }
   ],
   "source": [
    "# model trained with fixed learning rate\n",
    "# Set the hyperparameters and initialize the variables\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(69)\n",
    "# Assign random values to the weights and bias\n",
    "w = np.random.rand(1)\n",
    "b = np.random.rand(1)\n",
    "# Gradient Descent for w with fixed learning rate\n",
    "for i in range(epochs * 10000):\n",
    "    # Calculate the gradient of w\n",
    "    dW = 2 * (x_train_np * (w * x_train_np + b - y_train_np)).mean()\n",
    "    # Update the weights\n",
    "    w -= learning_rate * dW\n",
    "    # Recalculate y_pred after updating weights\n",
    "    y_pred = w * x_train_np + b\n",
    "    # Calculate the cost using Mean Squared Error (MSE)\n",
    "    cost = mean_squared_error(y_train_np, y_pred)\n",
    "    # Show the cost every 1000 iterations\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"iteration {i}, Cost: {cost:.2f}\", \"Weight: \", w, \"gradient of w: \", dW)\n",
    "# Gradient Descent for b with fixed learning rate\n",
    "for i in range(epochs * 10000):\n",
    "    # Calculate the gradient of b\n",
    "    dB = 2 * ((w * x_train_np + b - y_train_np)).mean()\n",
    "    # Update the bias\n",
    "    b -= learning_rate * dB\n",
    "    # Recalculate y_pred after updating weights and bias\n",
    "    y_pred = w * x_train_np + b\n",
    "    # Calculate the cost using Mean Squared Error (MSE)\n",
    "    cost = mean_squared_error(y_train_np, y_pred)\n",
    "    # Show the cost every 1000 iterations\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"iteration {i}, Cost: {cost:.2f}\", \"Bias: \", b, \"gradient of b: \", dB)\n",
    "# Calculate the cost using Mean Squared Error (MSE) for testing data\n",
    "y_test_pred_fixl = w * x_test.to_numpy() + b\n",
    "cost = mean_squared_error(y_test, y_test_pred_fixl)\n",
    "# Show the cost\n",
    "# Calculate the cost using Mean Squared Error (MSE) for testing data\n",
    "cost = mean_squared_error(y_test, y_test_pred_fixl)x\n",
    "# Show the cost\n",
    "print(\"Cost on test data: \", cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result, we can discover that the cost of model with fixed learning rate has a sightly higher cost (250.65291767685522) when predicting with test datas than adaptive learning rate (248.44936253622524). However, there is still no solid evidents to prove their correlations, the current result can be explained through variables other than learning rate. Still, since adaptive learning rate have proved useful for reducing test errors in studies as reducing training loss in training process [2]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foot notes: \n",
    "[1] Li Shen et al., A Unified Analysis of AdaGrad with Weighted Aggregation and Momentum Acceleration, arXiv preprint arXiv:1808.03408 (August 9, 2018), https://arxiv.org/pdf/1808.03408, accessed April 15, 2025.\n",
    "[2] Tomoumi Takase, Satoshi Oyama, and Masahito Kurihara, Effective Neural Network Training with Adaptive Learning Rate Based on Training Loss, Neural Networks 101 (May 2018): 68, https://doi.org/10.1016/j.neunet.2018.01.016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliography: (Please be adviced that there are some materials Haven't appeared on footnotes because my project are mainly based on them and I am unable to identify which part they contribute exactly.)\n",
    "\n",
    "GrandmaCan -. \"  Machine Learning3 |  AI | Python |  |  #AI #ML # .\" YouTube video, 257:04. \n",
    "Published 19th April, 2023. Accessed April 14, 2025. https://www.youtube.com/watch?v=wm9yR1VspPs.\n",
    "\n",
    "Hsieh, Chenghsi. Python Machine Learning (by  Sebastian Raschka, 2019) Youtube playlist, 2019. Accessed April 14, 2025. https://www.youtube.com/playlist?list=PL8xPPUJdubH7jx4wkkX1rvEcp5hmmK-co\n",
    "\n",
    "Lee, Hung-yi. 2021(). YouTube playlist, 2021. Accessed April 14, 2025. https://www.youtube.com/playlist?list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J.\n",
    "Shen, Li, Congliang Chen, Fangyu Zou, Zequn Jie, Ju Sun, and Wei Liu. A Unified Analysis of AdaGrad with Weighted Aggregation and Momentum Acceleration. arXiv     preprint arXiv:1808.03408 (August 9, 2018). https://arxiv.org/pdf/1808.03408. Accessed April 15, 2025.\n",
    "\n",
    "Takase, Tomoumi, Satoshi Oyama, and Masahito Kurihara. Effective Neural Network Training with Adaptive Learning Rate Based on Training Loss. Neural Networks 101 (May 2018): 6878. https://doi.org/10.1016/j.neunet.2018.01.016."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
